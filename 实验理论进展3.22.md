实验在年前两天其实就遇到问题了，这个问题至今没解决。问题的核心是目前的G无法表达频率偏移这个特征。

然后我就走了很多路，改进了很多。比较重大的改进，一是换了一种思路进行识别，将指纹转换成图像，从一维识别变为二维识别。     二是更换了训练方式，训练速度大大提升。   三是将频率抖动加入实验中抛弃原有的频率偏移识别。



而实验理论是这段时间进展迅速的，主要是以下几方面的进展：

1.为什么使用1x1卷积，这个是最后理解的，也是最重要的。

2.为什么之前的尝试不行，包括（CNN转换成图像进行识别，迁移学习，VAE-GAN，师兄的LSTM-CNN）。

3.目前矛盾的在哪里。



按照时间顺序去说：

一是我也有尝试不同的路，包括最早的将输入数据转换成图像，期待从判别器回来的梯度更新可以更好地表达出来，不可以。然后尝试了VAE-GAN，VAE是和GAN齐名的生成结构，期待通过编码器解码器这种结构你和能力更强可以拟合出来，我成功一步一步地把代码写出来了，可以生成非常不错的手写体了，但是生成QPSK数据还是不行，而就在这里我发现了一个关键点，之前总是关注“生成”，查找关于生成模型，生成网络结构的资料，但是我这里的并不是生成，因为我想控制输入数据而不是从隐空间中抽出来的，我想要的其实是“微调”，我想用网络实现微调这种功能，当然在深度学习里说微调其实一般指代网络结构固定对其中参数的微调，也就是迁移学习中所指微调，而迁移学习和我这个定义上很符合，都是数据集相似但是不相同，希望同个一个数据集训练的网络可以用在另一个数据集，当然后者我是不需要的，庆幸地是迁移学习也有基于对抗的迁移学习，而我在这里学习到了为什么我的之前的尝试都不行，基于对抗的迁移学习最终目地是两个空间的数据经过同一个特征提取器，判决器无法识别。

而我的问题就在这，我使用各种网络做G实际上只做了一步将数据经过特征提取器到达隐空间（开始我会用特征空间去表述，但是最近我发现用隐空间去表述更为恰当）而无法从隐空间这个低维数据提到高维数据变成原始空间。（所以这条路的困境在于不知道从隐空间还原到原始空间的方法，在网上没有找到中文信息，解码器中的反卷积更是可笑，深度学习里面的反卷积就是卷积而已）

其实到这里，这条路我已经不想走了，因为我已经知道了为什么要用1x1卷积了，最终的在于1x1卷积抽象出来是原始空间的变换，他并没有将数据变到隐空间中，进一步的我又推导了1x1卷积公式，并将qpsk的值带入发现了另一个好处，就是一三象限参数相反，二四象限参数相反，而且不同象限参数有一定规律，这就直接导致，1x1卷积可以表达IQ不平衡特征，并且解码正确。1x1实际上是对单个点的处理，你给他四种点最终也是四种点，正是对单个点处理的特点使他无法表达CFO。

其实到此为止，我还有一个疑问，为什么VAE-GAN可以生成可以欺骗的图片，而且可以画出来，而我这个为什么不行，这几天我从网上找资料，翻原来我记的吴恩达的笔记，终于找到答案，答案是图像卷积后达到特征空间而不是隐空间，如果可视化表示的话，经过卷积层后，每个通道画出图片都是一个特征，可能是竖线，横折，特征空间中还是有意义的，但是需要强调的是这个特征空间是牺牲了次要因素（至少是网络认为的次要因素）想表达什么就用几个特征空间拼接。

而我把指纹数据转换图像后，也只能学到“主要特征”，这个主要特征可不是我们认为IQ不平衡，CFO。一般来说是“颜色”波动大的地方，某种颜色的边缘，而这些可能是也可能不是我们要的主要特征，但是在池化过程中网络认为的不重要的因素都被忽略了所以前面我说是隐空间。（可视化去看，将数值变换为颜色）

另一个问题在解码正确问题，这种强制性可能会让在接收机那里看感觉是对的，但是解码就会出现问题，正则项或者这种强制操作本质是缩小解空间，不只是解码时候当你变换CFO，网络依然不能成功训练（关于正则项对于解码的影响我理解还没有到位，但是有一种方法可以检测解码是否能成功，就是看经过G未经过信道前那张星座图，变化前后一定要在同一象限，这样只能说理论上可以解码成功，但是经过衰落噪声还能不能解码正确就看后期处理了，但是开始一定要对，如果开头都不对后面肯定不对。）



以上是我从年前两天到目前为止的进展，那么我总结一下这个问题的矛盾在哪里，一句话可以总结

输入可控---星座图验证---解码正确  之间的矛盾，理论推导已经推导到这了。



3.18和老师讨论，主要解决了关于CFO理论部分，目前已经将CFO通过matlab展示出来了，对于G应该完成的任务也做了标识，但是具体怎么植入到G中去完成，目前还没有太好的想法，想在的想法是输入一个点，输出一个点，输出一个点，经过前后点的差异算出来delta f在乘到序列里去判别，让D不断返回来指导，但是这样的话强化学习更好。但是我想双特征嘛，所以还要用matlab做一下IQ不平衡的，看一下影响。

3.18晚，又把IQ不平衡内容做了，明白了相位不平衡和幅度不平衡具体影响了哪些方面。

3.19日，今天手推公式想看如何让G表达N次序，尝试了集中办法都在理论上否定了，知道了CFO理论，去手推这部分内容就变得简单了，但是目前可以G必须具有拟合e^j2pi * n * f的能力，且数据维度不能减小。

如果用4x1卷积核可以对CFO进行调整，但是用了4x1卷积核，唯独变小了，想扩维度就要添零变成了我之前说的到达特征空间无法再返回原始空间中，所以网络本身要具有记忆性而且核还是要1x1保证维度不缩小。



###RNN-LSTM###

RNN

<img src="D:\research_workshop_new\GAN-RFF\实验理论进展\实验理论进展3.20.assets\image-20210320152533162.png" alt="image-20210320152533162" style="zoom: 50%;" />

输出 **h'** 与 **x** 和 **h** 的值都相关。

而 **y** 则常常使用 **h'** 投入到一个线性层（主要是进行维度映射）然后使用softmax进行分类得到需要的数据。

对这里的**y**如何通过 **h'** 计算得到往往看具体模型的使用方式。

<img src="D:\research_workshop_new\GAN-RFF\实验理论进展\实验理论进展3.20.assets\image-20210320152624077.png" alt="image-20210320152624077" style="zoom:50%;" />

(参数应该不一样，这个同一个函数应该值都是一套)



LSTM

长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。（这个东西就跟卷积网络一样，卷积网络深度大，梯度就穿不过去了就出现了梯度消失和梯度爆炸问题，所以提出RESnet解决问题，而RNN用LSTM改进）



<img src="D:\research_workshop_new\GAN-RFF\实验理论进展\实验理论进展3.20.assets\image-20210320153437389.png" alt="image-20210320153437389" style="zoom: 50%;" />

![image-20210320153538414](D:\research_workshop_new\GAN-RFF\实验理论进展\实验理论进展3.20.assets\image-20210320153538414.png)



今天学习了LSTM，GRU也成功将代码调试出来了，但是结果不对，相差非常多。

目前是前面两个残差块学习IQ特征，后面GRU学习CFO特征，但是CFO输出范围太大了，这个目前不知道原因，已经到了±6的底部，而且我的输入是加了一个随时间（点数）偏移的值，感觉应该去掉。更重要的是我的接收机判决器是用二维卷积图像识别方法，很有可能返回的梯度不够有效。

https://zhuanlan.zhihu.com/p/34203833

https://blog.csdn.net/qq_37150124/article/details/109612445?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control



3.21没有进展。

3.22

今天测试了三层全连层，结果根本不对，但是并不能完全否认这条路就是不对的，因为我目前是分开处理的，并不是以块处理这种形式。

此外我还想到对于GRU还是要再确认一下函数中参数的意义，其实我们希望是450个GRU。输出450个值，而不是一个GRU被运行450遍。